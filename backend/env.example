# LLM Provider Configuration
# Options: "openai" or "local"
LLM_PROVIDER=openai

# OpenAI Configuration (if using OpenAI)
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-5-nano

# Local Model Configuration (if using local models via Ollama)
LOCAL_MODEL_NAME=llama3
LOCAL_MODEL_BASE_URL=http://localhost:11434